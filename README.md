# Infra-worker

`Infra-worker`는 서버리스 아키텍처에서 **작업 실행**과 **결과 처리**를 담당하는 Python 기반의 워커입니다. 이 프로젝트는 S3에서 파일을 다운로드하고, Docker 컨테이너에서 작업을 실행하며, 결과를 Redis와 S3에 업로드하는 등의 작업을 처리합니다. 또한 Prometheus를 사용하여 작업의 성과를 모니터링합니다.

## 주요 기능

### 1. SQS 메시지 처리
- **AWS SQS(Long Polling)**: `NanoAgent`는 AWS SQS 큐에서 메시지를 수신하여 작업을 처리합니다. SQS는 안정적인 메시징 서비스로, 메시지가 대기 중일 때 에이전트가 이를 받아 작업을 처리합니다. 수신한 메시지는 JSON 형식으로 파싱되어 `TaskMessage` 객체로 변환됩니다.
- **작업 처리**: 각 작업은 고유한 `requestId`와 관련된 데이터를 포함하고 있으며, 이를 기반으로 실제 실행이 이루어집니다.

### 2. Docker 컨테이너 워밍 풀
- **콜드 스타트 문제 해결**: `NanoAgent`는 Docker 컨테이너를 미리 시작하여 **콜드 스타트** 문제를 방지합니다. 다양한 언어(예: Python, C++, Node.js, Go)의 작업을 실행할 수 있도록 설정된 `Warm Pool`에서 미리 컨테이너를 시작하고, 필요한 작업을 빠르게 처리할 수 있습니다.
- **자동 컨테이너 관리**: 워밍 풀에 컨테이너가 부족할 경우, 자동으로 새로운 컨테이너를 생성하여 풀에 추가됩니다. 이를 통해 대기 시간을 최소화하고 성능을 최적화할 수 있습니다.

### 3. 작업 실행 및 결과 처리
- **S3에서 코드 다운로드**: `TaskExecutor`는 각 작업에 필요한 코드를 S3에서 다운로드합니다. 작업 파일은 ZIP 형식으로 저장되며, 이를 안전하게 추출하여 실행합니다.
- **Zip Slip 방지**: ZIP 파일을 추출할 때, 디렉토리 탐색에 의한 보안 취약점을 방지하기 위해 **Zip Slip** 방지 코드를 적용합니다. 이는 추출된 파일이 예상된 디렉토리 구조 내에서만 접근되도록 제한합니다.
- **Docker에서 실행**: 다운로드한 코드 파일은 Docker 컨테이너 내에서 실행됩니다. 각 작업은 동적으로 할당된 메모리와 CPU 자원을 기반으로 실행되며, 메모리 최적화 및 성능을 고려한 설정이 이루어집니다.

### 4. 메모리 최적화 및 비용 절감
- **메모리 분석**: 작업 실행 중 컨테이너에서 사용된 메모리를 추적하고, 메모리 사용 패턴을 분석하여 **최적화 팁**을 제공합니다. 예를 들어, 사용된 메모리가 할당량보다 적을 경우, 메모리 할당을 줄여 비용을 절감할 수 있습니다.
- **비용 절감 제안**: `AutoTuner` 클래스는 사용된 메모리와 할당된 메모리를 비교하여 메모리 절감 팁을 제공합니다. 예를 들어, 메모리 사용량이 적을 경우, 할당된 메모리 양을 줄여 비용을 절감할 수 있는 방법을 안내합니다.
- **월간 절감액 계산**: 메모리 최적화를 통해 예상되는 **월간 절감액**도 계산하여 사용자에게 제공하며, 실제로 사용할 메모리와 비교하여 비용 효율적인 운영을 도와줍니다.

### 5. Prometheus Metrics
- **모니터링 및 메트릭 수집**: `NanoAgent`는 Prometheus와 통합되어 작업 처리에 대한 다양한 메트릭을 수집합니다. Prometheus 메트릭 서버는 기본적으로 포트 8000에서 실행되며, 다음과 같은 메트릭을 제공합니다:
  - **처리된 작업 수**: 각 상태별(성공, 실패, 에러)로 처리된 작업의 총 수.
  - **작업 실행 시간**: 각 작업의 실행 시간을 기록하며, 실행 시간이 길어진 작업에 대한 모니터링을 지원합니다.
  - **현재 실행 중인 작업 수**: 현재 진행 중인 작업의 수를 실시간으로 추적합니다.
- **효율적인 모니터링**: Prometheus를 사용하여 시스템의 효율성을 추적하고, 성능 개선의 기회를 식별할 수 있습니다. 예를 들어, CPU와 메모리 사용량, 작업 처리 대기 시간 등을 실시간으로 모니터링할 수 있습니다.

### 6. Redis를 통한 결과 처리
- **Pub/Sub 방식**: 각 작업이 완료되면, 결과는 Redis를 통해 **Pub/Sub** 방식으로 전파됩니다. 이를 통해 다른 시스템이나 컴포넌트가 실시간으로 결과를 수신할 수 있습니다.
- **Async 조회**: 작업 결과는 Redis에 저장되며, 사용자가 비동기적으로 결과를 조회할 수 있도록 **TTL (Time-to-Live)** 기능을 활용하여 일정 시간 동안 저장됩니다.
- **결과 저장**: 작업 결과는 S3에 업로드되어 저장되며, 각 작업의 고유한 URL을 반환하여 사용자가 결과를 손쉽게 조회할 수 있습니다.

### 7. S3 결과 업로드
- **작업 결과 저장**: `OutputUploader` 클래스는 각 작업의 결과를 S3 버킷에 업로드하고, 업로드된 파일들의 URL을 반환합니다. 이를 통해 사용자는 결과 파일을 안전하게 보관하고, 필요시 URL을 통해 파일을 다운로드할 수 있습니다.
- **파일 업로드 경로**: 결과 파일은 `outputs/{job_id}/{filename}` 형식으로 저장되며, 업로드 후 생성된 URL은 S3의 공개 URL 형식을 따릅니다.


   ```bash
   pip install -r requirements.txt
   ```

### 8. CloudWatch Integration
- **Peak Memory Metrics**: `CloudWatchPublisher`는 각 작업의 메모리 사용량을 `NanoGrid/FunctionRunner` 네임스페이스에 게시합니다.
- **Metric Details**:
  - `PeakMemoryBytes`: 작업 실행 중 기록된 최대 메모리 사용량 (Bytes).
  - Dimensions: `FunctionId`, `Runtime`.

### 9. LLM Usage Metering
- **Token Usage Tracking**: LLM 작업의 경우 `.llm_usage_stats.jsonl` 파일에서 토큰 사용량(Prompt Evaluation, Evaluation Count)을 수집합니다.
- **Billing Data**: 수집된 토큰 수는 `ExecutionResult`에 포함되어 과금 및 사용량 분석에 활용됩니다.
